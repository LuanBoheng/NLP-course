{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.文件读取\n",
    "- !shell command 可以再 jupyter 里面执行 shell 命令\n",
    "- wiki 数据提取\n",
    "- pandas读取文件。常见中文编码方式（e.g. 'gb18030'）。\n",
    "- pandas对表中数据进行filter（titanic_train）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week2_recode.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.正则表达式\n",
    "- html 文件中用正则抓取 http url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.n-gram\n",
    "用n-gram计算句子、短语的概率\n",
    "### 3.1 词频统计 (BOW)\n",
    "- 生成可以统计词频的函数的函数（lisp风格的变量作用于trick）\n",
    "- 画出词频的分布曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Good–Turing frequency estimation\n",
    "reference: \n",
    "https://www.wikiwand.com/en/Good%E2%80%93Turing_frequency_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.机器学习基础\n",
    "- linear regression推导\n",
    "- 实现梯度下降，及其可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assumption for linear regression:\n",
    "\n",
    "$Y\\sim N(wx,\\sigma^2)\\equiv P_{w,\\sigma^2}(y|x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp\\left[-\\frac{(y-wx)^2}{2\\sigma^2}\\right]$\n",
    "\n",
    "MLE for all instanse in the training set with the size of n:\n",
    "\n",
    "$\\hat{w} = argmax_w \\prod_{i=1}^n P_{w,\\sigma^2}(y_i|x_i) = argmax_w \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\prod_{i=1}^n exp\\left[-\\frac{(y_i-wx_i)^2}{2\\sigma^2}\\right]$\n",
    "\n",
    "take logrithm on both sides:\n",
    "\n",
    "$\\hat{w} = argmax_w \\sum_{i=1}^n - [(y_i-wx_i)^2 - 2\\sigma^2] = argmin_w \\sum_{i=1}^n (y_i-wx_i)^2 $\n",
    "\n",
    "\n",
    "\n",
    "so linear regression model:\n",
    "\n",
    "$y=\\hat{w}x \\qquad s.t. \\quad \\hat{w} =argmin_w \\sum_{i=1}^n (y_i-wx_i)^2$\n",
    "\n",
    "define the loss function:\n",
    "\n",
    "$L(w) = \\sum_{i=1}^n (y_i-wx_i)^2 = ||Xw-Y||^2 = ||N((\\hat{w}-w)X,\\sigma^2)||^2$\n",
    "\n",
    "gradient of loss function\n",
    "\n",
    "$\\bigtriangledown L =\\frac{\\partial{L}}{\\partial{w}} = 2X^T(Xw-Y)$\n",
    "\n",
    "---\n",
    "\n",
    "1.close form solution:\n",
    "\n",
    "   $\\bigtriangledown L = 0 \\qquad \\equiv \\qquad  2X^T(Xw-Y) = 0$\n",
    "   \n",
    "   $X_{n*d},w_{d*1},Y_{n*1}$\n",
    "\n",
    "   $w = (X^TX)^{-1}X^TY$\n",
    "\n",
    "   complexity ananlysis:\n",
    "\n",
    "   $temp1_{d*d} = X^TX \\rightarrow O(n^{2.3728639})$\n",
    "\n",
    "   $temp2_{d*d} = temp1^{-1}\\rightarrow O(n^{2.3728639})$\n",
    "\n",
    "   $temp3_{d*1}=X^TY \\rightarrow O(n^{d*n*1})$\n",
    "\n",
    "   $result = temp2*temp3 \\rightarrow O(d*d*1)$\n",
    "\n",
    "   overall complexity is $O(n^{2.3728639})$\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "2.gradient desent\n",
    "\n",
    "   $w_{t+1}= w_{t}-\\eta\\bigtriangledown L $\n",
    "\n",
    "   $w_{t+1}= w_{t}-\\eta X^T(Xw-Y)$\n",
    "\n",
    "   complexity ananlysis:\n",
    "\n",
    "   $temp1_{n*1} = Xw \\rightarrow O(n*d*1)$\n",
    "\n",
    "   $temp2_{n*1} = temp1-Y \\rightarrow O(n)$\n",
    "\n",
    "   $gradient_{d*1} = X^Ttemp2 \\rightarrow O(d*n*1)$\n",
    "\n",
    "   repeat k iteration step\n",
    "\n",
    "   Overall complexity is $O(k*d*n)$, where k<<n, d<<n\n",
    "\n",
    "\n",
    "\n",
    "references of matrix computation: https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
